{
  "S1": {
    "description": "Q-learning, neutral vs neutral (Baseline)",
    "metadata": {
      "exp_id": "S1",
      "config": {
        "algorithm": "q_learning",
        "mode": "self_play",
        "personality_a": "neutral",
        "personality_b": "neutral",
        "description": "Baseline \u57fa\u51c6\u7ebf",
        "category": "shallow"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:00:49.986919",
      "command": "python scripts/train_shallow.py --algorithm q_learning --episodes 5000 --personality_a neutral --personality_b neutral --train_mode self_play --save_dir experiments/S1/checkpoints --log_interval 100 --save_interval 1000",
      "end_time": "2025-11-15T18:00:52.157688",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -1.331,
        -1.436,
        -1.43,
        -1.488,
        -1.51,
        -1.496,
        -1.477,
        -1.481,
        -1.479,
        -1.503,
        -1.502,
        -1.492,
        -1.502,
        -1.517,
        -1.498,
        -1.478,
        -1.482,
        -1.47,
        -1.481,
        -1.49,
        -1.518,
        -1.472,
        -1.496,
        -1.431,
        -1.465,
        -1.509,
        -1.484,
        -1.506,
        -1.471,
        -1.482,
        -1.483,
        -1.497,
        -1.482,
        -1.492,
        -1.495,
        -1.446,
        -1.494,
        -1.504,
        -1.478,
        -1.475,
        -1.454,
        -1.489,
        -1.494,
        -1.522,
        -1.487,
        -1.508,
        -1.466,
        -1.467,
        -1.472,
        -1.462
      ],
      "rewards_b": [
        -0.836,
        -0.775,
        -0.762,
        -0.736,
        -0.749,
        -0.749,
        -0.757,
        -0.758,
        -0.778,
        -0.755,
        -0.751,
        -0.755,
        -0.769,
        -0.736,
        -0.755,
        -0.762,
        -0.749,
        -0.761,
        -0.752,
        -0.741,
        -0.746,
        -0.755,
        -0.745,
        -0.768,
        -0.762,
        -0.747,
        -0.745,
        -0.751,
        -0.761,
        -0.763,
        -0.749,
        -0.747,
        -0.747,
        -0.757,
        -0.752,
        -0.776,
        -0.754,
        -0.751,
        -0.765,
        -0.762,
        -0.751,
        -0.761,
        -0.748,
        -0.751,
        -0.747,
        -0.741,
        -0.758,
        -0.752,
        -0.776,
        -0.768
      ],
      "lengths": [
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        2.9,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        2.9,
        2.9,
        3.0,
        3.0,
        2.9,
        3.0,
        2.9,
        2.9,
        3.0,
        2.9,
        3.0,
        2.9,
        3.0,
        2.9,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        2.9,
        3.0,
        3.0,
        3.0,
        2.9,
        3.0,
        2.9,
        3.0,
        3.0,
        3.0
      ],
      "final_emotion": -0.962,
      "final_trust": 0.01,
      "final_conflict": 0.976
    }
  },
  "S2": {
    "description": "Q-learning, impulsive vs sensitive",
    "metadata": {
      "exp_id": "S2",
      "config": {
        "algorithm": "q_learning",
        "mode": "self_play",
        "personality_a": "impulsive",
        "personality_b": "sensitive",
        "description": "\u51b2\u7a81\u6700\u6fc0\u70c8\u7ec4\u5408 (Most intense conflict combination)",
        "category": "shallow"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:00:52.158133",
      "command": "python scripts/train_shallow.py --algorithm q_learning --episodes 5000 --personality_a impulsive --personality_b sensitive --train_mode self_play --save_dir experiments/S2/checkpoints --log_interval 100 --save_interval 1000",
      "end_time": "2025-11-15T18:00:54.092597",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -1.378,
        -1.413,
        -1.455,
        -1.426,
        -1.413,
        -1.446,
        -1.436,
        -1.445,
        -1.474,
        -1.478,
        -1.41,
        -1.406,
        -1.445,
        -1.468,
        -1.44,
        -1.458,
        -1.418,
        -1.483,
        -1.446,
        -1.449,
        -1.455,
        -1.472,
        -1.466,
        -1.468,
        -1.489,
        -1.442,
        -1.414,
        -1.456,
        -1.5,
        -1.438,
        -1.51,
        -1.454,
        -1.475,
        -1.444,
        -1.481,
        -1.457,
        -1.416,
        -1.471,
        -1.478,
        -1.454,
        -1.461,
        -1.487,
        -1.435,
        -1.451,
        -1.458,
        -1.435,
        -1.484,
        -1.458,
        -1.457,
        -1.432
      ],
      "rewards_b": [
        -0.753,
        -0.757,
        -0.752,
        -0.755,
        -0.771,
        -0.762,
        -0.779,
        -0.748,
        -0.744,
        -0.756,
        -0.756,
        -0.76,
        -0.768,
        -0.75,
        -0.758,
        -0.77,
        -0.756,
        -0.759,
        -0.761,
        -0.741,
        -0.773,
        -0.747,
        -0.752,
        -0.747,
        -0.751,
        -0.759,
        -0.76,
        -0.747,
        -0.75,
        -0.746,
        -0.749,
        -0.745,
        -0.753,
        -0.744,
        -0.747,
        -0.747,
        -0.775,
        -0.758,
        -0.75,
        -0.744,
        -0.755,
        -0.729,
        -0.765,
        -0.751,
        -0.748,
        -0.764,
        -0.749,
        -0.752,
        -0.757,
        -0.764
      ],
      "lengths": [
        3.1,
        2.9,
        3.0,
        2.8,
        2.8,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.8,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        3.0,
        2.9,
        2.9,
        3.0,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.8,
        3.0,
        2.9,
        3.0,
        2.9,
        2.9,
        2.8,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.9,
        2.9,
        3.0,
        2.9,
        2.9,
        2.8
      ],
      "final_emotion": -0.962,
      "final_trust": 0.014,
      "final_conflict": 0.974
    }
  },
  "S3": {
    "description": "Q-learning, impulsive vs impulsive",
    "metadata": {
      "exp_id": "S3",
      "config": {
        "algorithm": "q_learning",
        "mode": "self_play",
        "personality_a": "impulsive",
        "personality_b": "impulsive",
        "description": "\u6781\u7aef\u51b2\u7a81 (Extreme conflict)",
        "category": "shallow"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:00:54.093183",
      "command": "python scripts/train_shallow.py --algorithm q_learning --episodes 5000 --personality_a impulsive --personality_b impulsive --train_mode self_play --save_dir experiments/S3/checkpoints --log_interval 100 --save_interval 1000",
      "end_time": "2025-11-15T18:00:56.012032",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -1.331,
        -1.394,
        -1.417,
        -1.423,
        -1.451,
        -1.425,
        -1.442,
        -1.445,
        -1.423,
        -1.464,
        -1.453,
        -1.435,
        -1.437,
        -1.451,
        -1.448,
        -1.493,
        -1.463,
        -1.454,
        -1.485,
        -1.421,
        -1.416,
        -1.461,
        -1.45,
        -1.44,
        -1.453,
        -1.439,
        -1.452,
        -1.436,
        -1.472,
        -1.417,
        -1.454,
        -1.427,
        -1.451,
        -1.415,
        -1.454,
        -1.454,
        -1.432,
        -1.459,
        -1.459,
        -1.479,
        -1.471,
        -1.392,
        -1.48,
        -1.472,
        -1.477,
        -1.463,
        -1.475,
        -1.419,
        -1.395,
        -1.458
      ],
      "rewards_b": [
        -0.801,
        -0.758,
        -0.79,
        -0.76,
        -0.755,
        -0.756,
        -0.761,
        -0.767,
        -0.769,
        -0.75,
        -0.763,
        -0.758,
        -0.762,
        -0.753,
        -0.74,
        -0.772,
        -0.744,
        -0.748,
        -0.765,
        -0.779,
        -0.771,
        -0.745,
        -0.754,
        -0.769,
        -0.745,
        -0.742,
        -0.736,
        -0.743,
        -0.757,
        -0.78,
        -0.745,
        -0.76,
        -0.734,
        -0.752,
        -0.76,
        -0.781,
        -0.763,
        -0.751,
        -0.744,
        -0.743,
        -0.744,
        -0.771,
        -0.744,
        -0.755,
        -0.75,
        -0.757,
        -0.745,
        -0.76,
        -0.773,
        -0.749
      ],
      "lengths": [
        2.8,
        2.9,
        3.0,
        2.8,
        2.8,
        2.8,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.8,
        2.9,
        2.8,
        3.0,
        2.9,
        2.9,
        3.0,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.9,
        2.8,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.8,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.9,
        2.9,
        2.9,
        2.9,
        2.9,
        2.8,
        2.8,
        2.9
      ],
      "final_emotion": -0.965,
      "final_trust": 0.014,
      "final_conflict": 0.975
    }
  },
  "S4": {
    "description": "Q-learning, neutral vs avoidant",
    "metadata": {
      "exp_id": "S4",
      "config": {
        "algorithm": "q_learning",
        "mode": "self_play",
        "personality_a": "neutral",
        "personality_b": "avoidant",
        "description": "\u51b7\u6218\u6a21\u5f0f (Cold war mode)",
        "category": "shallow"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:00:56.012597",
      "command": "python scripts/train_shallow.py --algorithm q_learning --episodes 5000 --personality_a neutral --personality_b avoidant --train_mode self_play --save_dir experiments/S4/checkpoints --log_interval 100 --save_interval 1000",
      "end_time": "2025-11-15T18:00:58.048459",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -1.359,
        -1.419,
        -1.386,
        -1.497,
        -1.469,
        -1.468,
        -1.462,
        -1.518,
        -1.477,
        -1.438,
        -1.485,
        -1.474,
        -1.475,
        -1.482,
        -1.468,
        -1.472,
        -1.435,
        -1.491,
        -1.464,
        -1.477,
        -1.502,
        -1.529,
        -1.471,
        -1.484,
        -1.478,
        -1.467,
        -1.479,
        -1.481,
        -1.445,
        -1.484,
        -1.504,
        -1.488,
        -1.467,
        -1.482,
        -1.448,
        -1.499,
        -1.465,
        -1.459,
        -1.471,
        -1.454,
        -1.498,
        -1.491,
        -1.445,
        -1.446,
        -1.474,
        -1.475,
        -1.477,
        -1.488,
        -1.502,
        -1.497
      ],
      "rewards_b": [
        -0.828,
        -0.765,
        -0.811,
        -0.743,
        -0.777,
        -0.77,
        -0.764,
        -0.742,
        -0.753,
        -0.778,
        -0.748,
        -0.777,
        -0.767,
        -0.763,
        -0.744,
        -0.751,
        -0.756,
        -0.77,
        -0.776,
        -0.773,
        -0.75,
        -0.739,
        -0.757,
        -0.757,
        -0.76,
        -0.758,
        -0.767,
        -0.754,
        -0.754,
        -0.757,
        -0.75,
        -0.756,
        -0.752,
        -0.755,
        -0.755,
        -0.759,
        -0.748,
        -0.76,
        -0.75,
        -0.75,
        -0.763,
        -0.746,
        -0.76,
        -0.75,
        -0.758,
        -0.762,
        -0.77,
        -0.758,
        -0.736,
        -0.743
      ],
      "lengths": [
        3.0,
        3.1,
        3.0,
        3.0,
        3.0,
        3.0,
        2.9,
        3.0,
        2.9,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        2.9,
        2.9,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        2.9,
        3.0,
        3.0,
        2.9,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        2.9,
        3.0,
        2.9,
        3.0,
        2.9,
        2.9,
        3.0,
        3.0,
        2.9,
        2.9,
        2.9,
        2.9,
        3.0,
        3.0,
        3.0,
        2.9
      ],
      "final_emotion": -0.972,
      "final_trust": 0.01,
      "final_conflict": 0.981
    }
  },
  "S5": {
    "description": "Q-learning, sensitive vs sensitive",
    "metadata": {
      "exp_id": "S5",
      "config": {
        "algorithm": "q_learning",
        "mode": "self_play",
        "personality_a": "sensitive",
        "personality_b": "sensitive",
        "description": "\u90fd\u654f\u611f,\u5bb9\u6613\u8bef\u89e3\u5347\u7ea7 (Both sensitive, easily misunderstood)",
        "category": "shallow"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:00:58.048947",
      "command": "python scripts/train_shallow.py --algorithm q_learning --episodes 5000 --personality_a sensitive --personality_b sensitive --train_mode self_play --save_dir experiments/S5/checkpoints --log_interval 100 --save_interval 1000",
      "end_time": "2025-11-15T18:01:00.041699",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -1.369,
        -1.399,
        -1.468,
        -1.465,
        -1.459,
        -1.482,
        -1.474,
        -1.473,
        -1.471,
        -1.475,
        -1.485,
        -1.483,
        -1.482,
        -1.471,
        -1.481,
        -1.468,
        -1.472,
        -1.492,
        -1.477,
        -1.484,
        -1.459,
        -1.474,
        -1.488,
        -1.48,
        -1.481,
        -1.474,
        -1.485,
        -1.494,
        -1.479,
        -1.462,
        -1.444,
        -1.465,
        -1.464,
        -1.506,
        -1.481,
        -1.474,
        -1.464,
        -1.484,
        -1.473,
        -1.451,
        -1.487,
        -1.447,
        -1.485,
        -1.47,
        -1.47,
        -1.484,
        -1.473,
        -1.471,
        -1.482,
        -1.49
      ],
      "rewards_b": [
        -0.846,
        -0.835,
        -0.755,
        -0.77,
        -0.771,
        -0.756,
        -0.754,
        -0.761,
        -0.77,
        -0.764,
        -0.749,
        -0.754,
        -0.736,
        -0.758,
        -0.751,
        -0.767,
        -0.758,
        -0.748,
        -0.753,
        -0.747,
        -0.752,
        -0.758,
        -0.749,
        -0.76,
        -0.756,
        -0.755,
        -0.749,
        -0.737,
        -0.749,
        -0.763,
        -0.788,
        -0.768,
        -0.757,
        -0.743,
        -0.752,
        -0.758,
        -0.77,
        -0.749,
        -0.751,
        -0.774,
        -0.751,
        -0.785,
        -0.754,
        -0.761,
        -0.777,
        -0.754,
        -0.75,
        -0.763,
        -0.747,
        -0.75
      ],
      "lengths": [
        3.3,
        3.3,
        3.1,
        3.0,
        3.1,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.0,
        3.1,
        3.1,
        3.0,
        3.0,
        3.0,
        3.1,
        3.1,
        3.1,
        3.0,
        3.1,
        3.0,
        3.1,
        3.1,
        3.0,
        3.1,
        3.0,
        3.0,
        3.1,
        3.0,
        3.0,
        3.1,
        3.0,
        3.0,
        3.1,
        3.0,
        3.0
      ],
      "final_emotion": -0.951,
      "final_trust": 0.015,
      "final_conflict": 0.968
    }
  },
  "S6": {
    "description": "Q-learning, fixed_opponent, impulsive vs sensitive",
    "metadata": {
      "exp_id": "S6",
      "config": {
        "algorithm": "q_learning",
        "mode": "fixed_opponent",
        "personality_a": "impulsive",
        "personality_b": "sensitive",
        "description": "A\u5b66\u4e60\u7406\u89e3\u654f\u611f\u578b\u4f34\u4fa3 (A learns to understand sensitive partner)",
        "category": "shallow"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:01:00.042252",
      "command": "python scripts/train_shallow.py --algorithm q_learning --episodes 5000 --personality_a impulsive --personality_b sensitive --train_mode fixed_opponent --save_dir experiments/S6/checkpoints --log_interval 100 --save_interval 1000",
      "end_time": "2025-11-15T18:01:01.873290",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -2.609,
        -2.401,
        -2.262,
        -2.125,
        -2.275,
        -2.327,
        -2.308,
        -2.301,
        -2.065,
        -2.147,
        -2.388,
        -2.225,
        -2.232,
        -2.34,
        -2.326,
        -2.145,
        -2.321,
        -2.464,
        -2.087,
        -2.199,
        -2.454,
        -1.919,
        -2.331,
        -2.268,
        -2.316,
        -2.216,
        -2.308,
        -2.316,
        -2.421,
        -2.351,
        -2.387,
        -2.357,
        -2.132,
        -2.1,
        -2.004,
        -2.188,
        -2.279,
        -2.393,
        -2.217,
        -2.225,
        -2.455,
        -1.953,
        -2.565,
        -2.215,
        -2.316,
        -2.293,
        -2.214,
        -2.371,
        -1.991,
        -2.396
      ],
      "rewards_b": [],
      "lengths": [
        6.0,
        5.3,
        5.0,
        4.4,
        4.8,
        4.8,
        4.8,
        4.9,
        4.4,
        4.5,
        4.9,
        4.7,
        4.8,
        4.9,
        4.9,
        4.6,
        4.9,
        5.1,
        4.3,
        4.7,
        5.1,
        4.1,
        4.9,
        4.8,
        4.9,
        4.6,
        4.8,
        4.8,
        5.2,
        4.8,
        5.0,
        4.9,
        4.4,
        4.4,
        4.3,
        4.6,
        4.8,
        5.1,
        4.7,
        4.7,
        5.1,
        4.1,
        5.4,
        4.6,
        4.9,
        4.9,
        4.6,
        4.9,
        4.2,
        5.0
      ],
      "final_emotion": -0.878,
      "final_trust": 0.119,
      "final_conflict": 0.879
    }
  },
  "S2_SARSA": {
    "description": "SARSA, impulsive vs sensitive",
    "metadata": {
      "exp_id": "S2_SARSA",
      "config": {
        "algorithm": "sarsa",
        "mode": "self_play",
        "personality_a": "impulsive",
        "personality_b": "sensitive",
        "description": "SARSA for comparison with S2 (Q-learning vs SARSA)",
        "category": "shallow"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:02:41.655707",
      "command": "python scripts/train_shallow.py --algorithm sarsa --episodes 5000 --personality_a impulsive --personality_b sensitive --train_mode self_play --save_dir experiments/S2_SARSA/checkpoints --log_interval 100 --save_interval 1000",
      "end_time": "2025-11-15T18:02:43.465081",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -1.025,
        -0.984,
        -0.929,
        -0.934,
        -0.971,
        -0.952,
        -0.943,
        -0.946,
        -0.977,
        -0.957,
        -0.93,
        -0.943,
        -0.971,
        -0.929,
        -0.968,
        -0.937,
        -0.958,
        -0.953,
        -0.961,
        -0.965,
        -0.955,
        -0.953,
        -0.944,
        -0.939,
        -0.946,
        -0.974,
        -0.944,
        -0.936,
        -0.959,
        -0.929,
        -0.93,
        -0.949,
        -0.958,
        -0.934,
        -0.934,
        -0.943,
        -0.945,
        -0.94,
        -0.932,
        -0.978,
        -0.939,
        -0.958,
        -0.949,
        -0.932,
        -0.937,
        -0.952,
        -0.937,
        -0.936,
        -0.958,
        -0.939
      ],
      "rewards_b": [
        -0.865,
        -0.894,
        -0.923,
        -0.904,
        -0.89,
        -0.9,
        -0.894,
        -0.897,
        -0.892,
        -0.885,
        -0.908,
        -0.898,
        -0.869,
        -0.915,
        -0.891,
        -0.909,
        -0.891,
        -0.897,
        -0.888,
        -0.899,
        -0.899,
        -0.906,
        -0.903,
        -0.895,
        -0.905,
        -0.896,
        -0.9,
        -0.898,
        -0.9,
        -0.902,
        -0.899,
        -0.902,
        -0.899,
        -0.899,
        -0.894,
        -0.89,
        -0.898,
        -0.899,
        -0.896,
        -0.9,
        -0.903,
        -0.892,
        -0.894,
        -0.905,
        -0.911,
        -0.888,
        -0.912,
        -0.892,
        -0.915,
        -0.888
      ],
      "lengths": [
        2.5,
        2.2,
        2.2,
        2.1,
        2.2,
        2.2,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.2,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.2,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.1,
        2.2,
        2.1
      ],
      "final_emotion": -0.867,
      "final_trust": 0.059,
      "final_conflict": 0.904
    }
  },
  "D1": {
    "description": "DQN, neutral vs neutral (Deep baseline)",
    "metadata": {
      "exp_id": "D1",
      "config": {
        "algorithm": "dqn",
        "mode": "self_play",
        "personality_a": "neutral",
        "personality_b": "neutral",
        "description": "\u6df1\u5ea6 baseline (Deep baseline)",
        "category": "deep"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:01:01.873725",
      "command": "python scripts/train_deep.py --algorithm dqn --episodes 5000 --personality_a neutral --personality_b neutral --train_mode self_play --save_dir experiments/D1/checkpoints --log_interval 100 --save_interval 1000 --history_length 10",
      "end_time": "2025-11-15T18:01:53.666298",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -0.852,
        -1.411,
        -1.52,
        -0.98,
        0.052,
        0.005,
        -0.181,
        -0.0,
        0.445,
        0.578,
        0.516,
        0.414,
        0.527,
        0.107,
        -0.125,
        -1.201,
        -1.425,
        -1.614,
        -1.484,
        -3.338,
        -3.514,
        -2.986,
        -2.454,
        -1.591,
        -1.75,
        -1.546,
        -1.034,
        0.156,
        1.105,
        1.247,
        1.426,
        1.428,
        1.044,
        0.962,
        1.25,
        1.336,
        -0.139,
        -0.164,
        -0.059,
        0.774,
        0.56,
        -1.621,
        -2.728,
        -3.119,
        -3.049,
        -2.396,
        -2.078,
        -2.143,
        -2.072,
        -2.48
      ],
      "rewards_b": [
        -0.575,
        -0.847,
        -0.72,
        -1.329,
        -2.259,
        -2.291,
        -2.139,
        -2.21,
        -3.018,
        -3.067,
        -2.684,
        -2.85,
        -3.041,
        -2.465,
        -2.177,
        -1.171,
        -0.786,
        -0.509,
        -0.386,
        0.993,
        1.348,
        0.731,
        0.045,
        -0.699,
        -0.529,
        -0.815,
        -1.41,
        -2.662,
        -3.766,
        -3.921,
        -3.986,
        -3.885,
        -3.577,
        -3.457,
        -3.814,
        -3.806,
        -2.72,
        -2.499,
        -2.479,
        -3.303,
        -3.106,
        -1.006,
        0.036,
        0.461,
        0.473,
        -0.156,
        -0.547,
        -0.539,
        -0.374,
        0.024
      ],
      "lengths": [
        6.4,
        4.0,
        3.3,
        4.8,
        6.7,
        8.8,
        9.2,
        11.6,
        17.3,
        17.6,
        16.5,
        16.4,
        17.4,
        15.4,
        16.9,
        18.6,
        19.4,
        19.8,
        19.9,
        15.7,
        13.9,
        16.4,
        17.6,
        15.9,
        16.1,
        17.6,
        16.9,
        16.1,
        17.3,
        16.7,
        16.2,
        16.1,
        16.7,
        16.0,
        16.6,
        15.8,
        15.8,
        15.7,
        16.8,
        16.5,
        16.4,
        17.3,
        18.1,
        17.9,
        18.1,
        19.9,
        19.5,
        19.6,
        18.3,
        17.3
      ],
      "final_emotion": -0.553,
      "final_trust": 0.582,
      "final_conflict": 0.486
    }
  },
  "D2": {
    "description": "DQN, impulsive vs sensitive",
    "metadata": {
      "exp_id": "D2",
      "config": {
        "algorithm": "dqn",
        "mode": "self_play",
        "personality_a": "impulsive",
        "personality_b": "sensitive",
        "description": "\u5bf9\u6bd4 shallow \u2192 deep \u4f18\u52bf (Comparison: shallow \u2192 deep advantage)",
        "category": "deep"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:01:53.667192",
      "command": "python scripts/train_deep.py --algorithm dqn --episodes 5000 --personality_a impulsive --personality_b sensitive --train_mode self_play --save_dir experiments/D2/checkpoints --log_interval 100 --save_interval 1000 --history_length 10",
      "end_time": "2025-11-15T18:02:38.741431",
      "status": "completed"
    },
    "training": {
      "episodes": [
        100,
        200,
        300,
        400,
        500,
        600,
        700,
        800,
        900,
        1000,
        1100,
        1200,
        1300,
        1400,
        1500,
        1600,
        1700,
        1800,
        1900,
        2000,
        2100,
        2200,
        2300,
        2400,
        2500,
        2600,
        2700,
        2800,
        2900,
        3000,
        3100,
        3200,
        3300,
        3400,
        3500,
        3600,
        3700,
        3800,
        3900,
        4000,
        4100,
        4200,
        4300,
        4400,
        4500,
        4600,
        4700,
        4800,
        4900,
        5000
      ],
      "rewards_a": [
        -0.966,
        -1.309,
        -1.235,
        -0.163,
        -0.036,
        -0.425,
        -0.298,
        -0.636,
        -0.092,
        -0.154,
        0.145,
        0.15,
        0.11,
        -0.322,
        -0.62,
        -1.067,
        -0.884,
        -1.1,
        -1.332,
        -1.07,
        -1.006,
        -1.111,
        -0.994,
        -0.952,
        -1.262,
        -1.347,
        -1.171,
        -1.356,
        -1.196,
        -1.121,
        -1.251,
        -0.752,
        -0.869,
        -0.341,
        0.132,
        0.503,
        0.461,
        0.335,
        0.556,
        0.641,
        0.832,
        0.705,
        0.585,
        -0.081,
        -1.395,
        -1.417,
        -1.834,
        -1.692,
        -1.444,
        -1.317
      ],
      "rewards_b": [
        -0.514,
        -0.837,
        -0.908,
        -1.718,
        -1.872,
        -1.733,
        -1.817,
        -1.693,
        -1.972,
        -2.059,
        -2.389,
        -2.324,
        -2.368,
        -2.051,
        -1.466,
        -1.035,
        -1.34,
        -1.308,
        -1.016,
        -1.344,
        -1.268,
        -1.145,
        -1.323,
        -1.152,
        -1.106,
        -0.867,
        -0.752,
        -0.61,
        -0.627,
        -1.07,
        -1.244,
        -1.757,
        -1.582,
        -2.184,
        -2.638,
        -3.003,
        -2.87,
        -2.791,
        -2.982,
        -3.09,
        -3.377,
        -3.183,
        -3.069,
        -2.41,
        -1.297,
        -1.179,
        -0.45,
        -0.521,
        -0.819,
        -1.149
      ],
      "lengths": [
        6.2,
        3.6,
        3.5,
        5.1,
        5.8,
        7.0,
        7.8,
        8.9,
        8.3,
        10.4,
        10.2,
        9.7,
        12.7,
        14.2,
        16.5,
        15.7,
        17.3,
        16.6,
        15.1,
        17.3,
        17.0,
        16.4,
        16.7,
        16.8,
        18.1,
        16.1,
        15.7,
        15.3,
        16.2,
        16.1,
        17.2,
        16.1,
        16.2,
        16.8,
        16.9,
        16.5,
        15.6,
        15.9,
        16.0,
        17.0,
        18.6,
        17.7,
        16.1,
        16.4,
        18.4,
        16.9,
        15.6,
        14.1,
        16.5,
        17.2
      ],
      "final_emotion": -0.616,
      "final_trust": 0.598,
      "final_conflict": 0.509
    }
  },
  "D3": {
    "description": "PPO, impulsive vs sensitive",
    "metadata": {
      "exp_id": "D3",
      "config": {
        "algorithm": "ppo",
        "mode": "self_play",
        "personality_a": "impulsive",
        "personality_b": "sensitive",
        "description": "PPO \u7a33\u5b9a\u7b56\u7565 (PPO stable strategy)",
        "category": "deep"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:02:38.742060",
      "command": "python scripts/train_deep.py --algorithm ppo --episodes 5000 --personality_a impulsive --personality_b sensitive --train_mode self_play --save_dir experiments/D3/checkpoints --log_interval 100 --save_interval 1000 --history_length 10",
      "end_time": "2025-11-15T18:02:40.319421",
      "status": "failed",
      "error": "Command '['python', 'scripts/train_deep.py', '--algorithm', 'ppo', '--episodes', '5000', '--personality_a', 'impulsive', '--personality_b', 'sensitive', '--train_mode', 'self_play', '--save_dir', 'experiments/D3/checkpoints', '--log_interval', '100', '--save_interval', '1000', '--history_length', '10']' returned non-zero exit status 1."
    },
    "training": {
      "episodes": [],
      "rewards_a": [],
      "rewards_b": [],
      "lengths": [],
      "final_emotion": -0.2,
      "final_trust": 0.6,
      "final_conflict": 0.3
    }
  },
  "D4": {
    "description": "PPO, sensitive vs sensitive",
    "metadata": {
      "exp_id": "D4",
      "config": {
        "algorithm": "ppo",
        "mode": "self_play",
        "personality_a": "sensitive",
        "personality_b": "sensitive",
        "description": "\u6d4b\u8bd5'\u60c5\u7eea\u7ec6\u817b\u7684\u4eba'\u4e92\u52a8\u6a21\u5f0f (Testing emotionally delicate interaction)",
        "category": "deep"
      },
      "num_episodes": 5000,
      "start_time": "2025-11-15T18:02:40.319860",
      "command": "python scripts/train_deep.py --algorithm ppo --episodes 5000 --personality_a sensitive --personality_b sensitive --train_mode self_play --save_dir experiments/D4/checkpoints --log_interval 100 --save_interval 1000 --history_length 10",
      "end_time": "2025-11-15T18:02:41.655192",
      "status": "failed",
      "error": "Command '['python', 'scripts/train_deep.py', '--algorithm', 'ppo', '--episodes', '5000', '--personality_a', 'sensitive', '--personality_b', 'sensitive', '--train_mode', 'self_play', '--save_dir', 'experiments/D4/checkpoints', '--log_interval', '100', '--save_interval', '1000', '--history_length', '10']' returned non-zero exit status 1."
    },
    "training": {
      "episodes": [],
      "rewards_a": [],
      "rewards_b": [],
      "lengths": [],
      "final_emotion": -0.2,
      "final_trust": 0.6,
      "final_conflict": 0.3
    }
  }
}